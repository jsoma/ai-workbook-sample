[
  {
    "objectID": "070-document-chatbots.html",
    "href": "070-document-chatbots.html",
    "title": "Chat with your documents - retrieval-augmented generation",
    "section": "",
    "text": "You’ve probably seen “Chat with your PDFs” or “ask your spreadsheets questions” and it leverages everything we’ve seen so far.\nPulls relevant pieces of content, sends it to the LLM along with the question, you get an answer.\nFeels VERY cool when you get the right result, but… you don’t always.\nSelf-driving car problem? But probably even worse, because are you actually going to read the document itself?\nHere are all the potential issues: a, b, c, d. And you have to ask yourself, is it worth it?\n\n\nare a lie"
  },
  {
    "objectID": "070-document-chatbots.html#citations",
    "href": "070-document-chatbots.html#citations",
    "title": "Chat with your documents - retrieval-augmented generation",
    "section": "",
    "text": "are a lie"
  },
  {
    "objectID": "headlines/conversations.html",
    "href": "headlines/conversations.html",
    "title": "Two-way conversations",
    "section": "",
    "text": "So far we’ve been very good at talking at our chatbot, but not thinking too much about what it says in return. It’s just a dumb intern, right? If we were working with a colleague, we’d probably approach things a little differently: even something as simple as “what do you think?” could take our piece in a new direction.\nNow it’s time to adjust our mindset to take better advantage of our AI tool. If you start to think of the chatbot as your boss instead of your employee, or your coworker instead of your intern, things get a lot more interesting!\n\n\n\n\n    \n\n\nWe’re going to combine elements of all of the sections we’ve been through so far:\n\nLong, details prompts\nBack-and-forth conversations\nMultiple angles or suggestions\n\nThe addition we’re making now making our conversations intentional. Previously we’ve only had conversations when things have gone wrong or we want an improvement or correct. This time we’re going to make the conversation the entire point.\n\n\n\n\n\n\nA prompt suggestion\n\n\n\nAct as an editor of the New York Times. You are going to help me write a headline. It is going to take several steps of a conversational process.\nFirst, ask me for the article. When requested, I will paste it in. Note that it might include image captions, ads, etc. Sorry for not cleaning it up!\nSecond, provide several options for angles that we can take for the headline and ask if I have a preference. Allow me to select one or provide another another suggestion. If I do neither, assume I want a mix of different angles.\nFinally, provide a list of five headlines. Provide suggestions of directions we could take in improvements, and ask if there is anything that is missing or any adjustments that I would like to have made.\n\n\nClick here to start the conversation 🔮\nThis is the part that, to me, feels a lot like magic. Your prompt is in some ways guidance to yourself instead of to the machine, and is forcing you to take into account each piece that you’ve decided (through the prompt) is important.\nYou could add a thousand-and-one other little snippets to the prompt, depending on what you feel is useful."
  },
  {
    "objectID": "headlines/conversations.html#prompting-for-conversations",
    "href": "headlines/conversations.html#prompting-for-conversations",
    "title": "Two-way conversations",
    "section": "",
    "text": "We’re going to combine elements of all of the sections we’ve been through so far:\n\nLong, details prompts\nBack-and-forth conversations\nMultiple angles or suggestions\n\nThe addition we’re making now making our conversations intentional. Previously we’ve only had conversations when things have gone wrong or we want an improvement or correct. This time we’re going to make the conversation the entire point.\n\n\n\n\n\n\nA prompt suggestion\n\n\n\nAct as an editor of the New York Times. You are going to help me write a headline. It is going to take several steps of a conversational process.\nFirst, ask me for the article. When requested, I will paste it in. Note that it might include image captions, ads, etc. Sorry for not cleaning it up!\nSecond, provide several options for angles that we can take for the headline and ask if I have a preference. Allow me to select one or provide another another suggestion. If I do neither, assume I want a mix of different angles.\nFinally, provide a list of five headlines. Provide suggestions of directions we could take in improvements, and ask if there is anything that is missing or any adjustments that I would like to have made.\n\n\nClick here to start the conversation 🔮\nThis is the part that, to me, feels a lot like magic. Your prompt is in some ways guidance to yourself instead of to the machine, and is forcing you to take into account each piece that you’ve decided (through the prompt) is important.\nYou could add a thousand-and-one other little snippets to the prompt, depending on what you feel is useful."
  },
  {
    "objectID": "headlines/rule-of-five.html",
    "href": "headlines/rule-of-five.html",
    "title": "Rule of five",
    "section": "",
    "text": "One way to iterate more quickly when using AI tools is the rule of five (or ten, or thirty, or ninety). Instead of asking for one headline at a time, ask ChatGPT for five headlines.\nAlong with getting more ideas set out in front of you, I’ve also found it to be helpful process for highlighting bias. I don’t (necessarily) mean what we normally think of as bias - think of it more like “habits” or “tendencies.” Maybe one person always writes sensationalist headlines, another person always uses colons and subheads.\n\n\n\n\n    \n\n\nWe’re going to start from the same headline generation prompt as before, but change it to be for five headlines instead of just one.\n\n\n\n\n\n\nA prompt suggestion\n\n\n\nYou are an editor at the New York Times. Write five headlines for the article below. The tone should be informed but approachable. Limit the headline to 70 characters.\nARTICLE:\n(paste the story in)\n\n\nClick here to use my article 🔮\nClear the chat 🔮\nThis is simple, this is easy. And nothing’s stopping us from asking for ten headlines or twenty headlines!\n\n\nThe five responses I got were pretty much all in the same vein:\n\n\nBronx Drug Market Thrives as City Battles Overdose Crisis\nFentanyl Fear Rises in NYC Amid Record Overdose Deaths\nIn Bronx Underpass, Open Drug Use and Rising Tensions\nBronx Tragedy: Fentanyl’s Shadow Over a Community in Crisis\nAmidst Drug Crisis, Bronx Residents Seek Safer Streets\n\n\nWhen you ask for five headlines instead of just one, the similarities really jump out at you! We’re being gently guided into a certain direction, even though the LLM doesn’t actually have a reason to send us in one direction or another (it can’t think, after all!).\nI think calling this “bias” is a bit much, but it’s a gentle reminder that AI tools come with baked-in assumptions and angles. If you don’t work hard to notice them, at the very least they’ll make all your content similar and boring!\n\n\n\n\n\n\nNotice how even though I asked ChatGPT to not use subheads or colons, it did anyway! You should expect the AI to ignore your instructions a good portion of the time.\n\n\n\nOne way to add a little diversity to the mix is to simply ask for it.\n\n\n\nAn extension of the simple “give us five” from above might be to explicitly ask ChatGPT for five markedly different options – in this case it might be five different angles or five different tones.\nEven if we aren’t making specific demands of the AI tool on how to break out of its habits, asking for different takes can go a long way in helping it happen.\n\n\n\n\n\n\nA prompt suggestion\n\n\n\nYou are an editor at the New York Times. Write five headlines for the story below. The tone should be informed but approachable. Limit the headline to 70 characters.\nHave each headline elicit a different emotional response or subject-matter concern from the reader. Label each headline with the emotion/concern.\nARTICLE:\n(paste the story in)\n\n\nClick here to use my article 🔮\nClear the chat 🔮\n\n\n\n\n\n\nLet’s take a look at the results I got:\n\n\nConcern: Public Safety: “Bronx Daycare Tragedy Highlights Rampant Drug Crisis in NYC”\nEmotion: Outrage: “Fentanyl Scourge Unchecked: Bronx Community Demands Action”\nEmotion: Compassion: “Amid Bronx Despair, a Plea for Help Against Drug Menace”\nConcern: Policy and Governance: “NYC Struggles with Drug Policy as Overdoses Soar, Communities Suffer”\nEmotion: Fear: “Bronx Nightmare: Fentanyl Threat Looms as Overdoses Rise”\n\n\nWhen you’re provided suggestions by the AI, it’s easy to just go along with them. But when you starting seeing the habits and tendencies and start asking for different angles, I feel like that’s when you start to realize “hey, we’re giving up a lot of control here!”\nIf the media has a certain way of talking about certain topics – which media critics like Alec Karakatsanis would very much agree – it takes a certain degree effort to break out of the typical framing.\nUsing an AI-generated headline can go both ways: since language models are just statistical predictions of the next word, they go above and beyond when it comes to reinforcing what’s “typical,” or the status quo of how a subject is discussed. But conversely, if we recognize that other angles might exist, it’s easy enough to prompt in directions we wouldn’t normally think about.\nIn our next step we go even further in having the AI help us generate more headlines and think critically about our angles."
  },
  {
    "objectID": "headlines/rule-of-five.html#exercise",
    "href": "headlines/rule-of-five.html#exercise",
    "title": "Rule of five",
    "section": "",
    "text": "We’re going to start from the same headline generation prompt as before, but change it to be for five headlines instead of just one.\n\n\n\n\n\n\nA prompt suggestion\n\n\n\nYou are an editor at the New York Times. Write five headlines for the article below. The tone should be informed but approachable. Limit the headline to 70 characters.\nARTICLE:\n(paste the story in)\n\n\nClick here to use my article 🔮\nClear the chat 🔮\nThis is simple, this is easy. And nothing’s stopping us from asking for ten headlines or twenty headlines!\n\n\nThe five responses I got were pretty much all in the same vein:\n\n\nBronx Drug Market Thrives as City Battles Overdose Crisis\nFentanyl Fear Rises in NYC Amid Record Overdose Deaths\nIn Bronx Underpass, Open Drug Use and Rising Tensions\nBronx Tragedy: Fentanyl’s Shadow Over a Community in Crisis\nAmidst Drug Crisis, Bronx Residents Seek Safer Streets\n\n\nWhen you ask for five headlines instead of just one, the similarities really jump out at you! We’re being gently guided into a certain direction, even though the LLM doesn’t actually have a reason to send us in one direction or another (it can’t think, after all!).\nI think calling this “bias” is a bit much, but it’s a gentle reminder that AI tools come with baked-in assumptions and angles. If you don’t work hard to notice them, at the very least they’ll make all your content similar and boring!\n\n\n\n\n\n\nNotice how even though I asked ChatGPT to not use subheads or colons, it did anyway! You should expect the AI to ignore your instructions a good portion of the time.\n\n\n\nOne way to add a little diversity to the mix is to simply ask for it.\n\n\n\nAn extension of the simple “give us five” from above might be to explicitly ask ChatGPT for five markedly different options – in this case it might be five different angles or five different tones.\nEven if we aren’t making specific demands of the AI tool on how to break out of its habits, asking for different takes can go a long way in helping it happen.\n\n\n\n\n\n\nA prompt suggestion\n\n\n\nYou are an editor at the New York Times. Write five headlines for the story below. The tone should be informed but approachable. Limit the headline to 70 characters.\nHave each headline elicit a different emotional response or subject-matter concern from the reader. Label each headline with the emotion/concern.\nARTICLE:\n(paste the story in)\n\n\nClick here to use my article 🔮\nClear the chat 🔮"
  },
  {
    "objectID": "headlines/rule-of-five.html#noticing-habits",
    "href": "headlines/rule-of-five.html#noticing-habits",
    "title": "Rule of five",
    "section": "",
    "text": "The five responses I got were pretty much all in the same vein:\n\n\nBronx Drug Market Thrives as City Battles Overdose Crisis\nFentanyl Fear Rises in NYC Amid Record Overdose Deaths\nIn Bronx Underpass, Open Drug Use and Rising Tensions\nBronx Tragedy: Fentanyl’s Shadow Over a Community in Crisis\nAmidst Drug Crisis, Bronx Residents Seek Safer Streets\n\n\nWhen you ask for five headlines instead of just one, the similarities really jump out at you! We’re being gently guided into a certain direction, even though the LLM doesn’t actually have a reason to send us in one direction or another (it can’t think, after all!).\nI think calling this “bias” is a bit much, but it’s a gentle reminder that AI tools come with baked-in assumptions and angles. If you don’t work hard to notice them, at the very least they’ll make all your content similar and boring!\n\n\n\n\n\n\nNotice how even though I asked ChatGPT to not use subheads or colons, it did anyway! You should expect the AI to ignore your instructions a good portion of the time.\n\n\n\nOne way to add a little diversity to the mix is to simply ask for it."
  },
  {
    "objectID": "headlines/rule-of-five.html#diversifying-your-results",
    "href": "headlines/rule-of-five.html#diversifying-your-results",
    "title": "Rule of five",
    "section": "",
    "text": "An extension of the simple “give us five” from above might be to explicitly ask ChatGPT for five markedly different options – in this case it might be five different angles or five different tones.\nEven if we aren’t making specific demands of the AI tool on how to break out of its habits, asking for different takes can go a long way in helping it happen.\n\n\n\n\n\n\nA prompt suggestion\n\n\n\nYou are an editor at the New York Times. Write five headlines for the story below. The tone should be informed but approachable. Limit the headline to 70 characters.\nHave each headline elicit a different emotional response or subject-matter concern from the reader. Label each headline with the emotion/concern.\nARTICLE:\n(paste the story in)\n\n\nClick here to use my article 🔮\nClear the chat 🔮"
  },
  {
    "objectID": "headlines/rule-of-five.html#reflection",
    "href": "headlines/rule-of-five.html#reflection",
    "title": "Rule of five",
    "section": "",
    "text": "Let’s take a look at the results I got:\n\n\nConcern: Public Safety: “Bronx Daycare Tragedy Highlights Rampant Drug Crisis in NYC”\nEmotion: Outrage: “Fentanyl Scourge Unchecked: Bronx Community Demands Action”\nEmotion: Compassion: “Amid Bronx Despair, a Plea for Help Against Drug Menace”\nConcern: Policy and Governance: “NYC Struggles with Drug Policy as Overdoses Soar, Communities Suffer”\nEmotion: Fear: “Bronx Nightmare: Fentanyl Threat Looms as Overdoses Rise”\n\n\nWhen you’re provided suggestions by the AI, it’s easy to just go along with them. But when you starting seeing the habits and tendencies and start asking for different angles, I feel like that’s when you start to realize “hey, we’re giving up a lot of control here!”\nIf the media has a certain way of talking about certain topics – which media critics like Alec Karakatsanis would very much agree – it takes a certain degree effort to break out of the typical framing.\nUsing an AI-generated headline can go both ways: since language models are just statistical predictions of the next word, they go above and beyond when it comes to reinforcing what’s “typical,” or the status quo of how a subject is discussed. But conversely, if we recognize that other angles might exist, it’s easy enough to prompt in directions we wouldn’t normally think about.\nIn our next step we go even further in having the AI help us generate more headlines and think critically about our angles."
  },
  {
    "objectID": "headlines/index.html",
    "href": "headlines/index.html",
    "title": "Prompting basics: generating headlines",
    "section": "",
    "text": "Prompting basics: generating headlines\nIn this section, we’re going to take a look at the most basic interaction you’ll have with AI: talking to a chatbot!\nWhile this section is technically based around writing headlines with ChatGPT, what you’re going to learn in the process is a lot more general (and useful!). Instead of just headlines, it’s about how you can talk to and use AI during the creative process, a.k.a. “prompt engineering.”\n\nTable of contents\nI recommend starting from the beginning and working your way through each section.\n\nBasic prompting, or how to have a conversation with your AI buddy\nPrompt Engineering, or getting it right the first time\nRule of five, how to break out of biased results (but no, not that bias)\nTwo-way conversations, having intentional interactions with your AI boss or coworker\nConclusion"
  },
  {
    "objectID": "headlines/conclusion.html",
    "href": "headlines/conclusion.html",
    "title": "The big reveal",
    "section": "",
    "text": "But now the important part: comparing the AI-generated headline(s) with the hand-crafted artisinal human-generated ones. How do the suggestions compare with the final headline the NYT used? 1 Let’s take a look:\n\nThe actual New York Times headline is far more vague, less fear-inducing, and doesn’t mention the Bronx at all. It makes it a story relevant to all New Yorkers, but doesn’t turn it into fearmongering clickbait.\nHonestly, I was shocked: it’s so far from anything that GPT suggested. Maybe your prompts got you closer, but I was certainly not that lucky.\n\n\nThis whole process made me think about a paper comparing story generation between humans and humans assisted by AI: 2\nStories written with AI assitance were scored as better than stories written by humans alone. Despite being worse, though, the human-writtens stories had a much wider range of ideas and concepts in them. AI guidance provided the authors a higher-scoring work, but at the expense of actually being unique!\nTo abuse a quote: “all human work improved by AI is alike; every purely human work is creative in its own way.”\nIn future chapters we’ll dig deeper into how AI tools like ChatGPT work, and how a side effect of their construction might mean that headline generation is the only thing they’re reasonably good at! So whether you were super excited or roundly unimpressed: get excited for a ride down to the bottom."
  },
  {
    "objectID": "headlines/conclusion.html#reflection",
    "href": "headlines/conclusion.html#reflection",
    "title": "The big reveal",
    "section": "",
    "text": "This whole process made me think about a paper comparing story generation between humans and humans assisted by AI: 2\nStories written with AI assitance were scored as better than stories written by humans alone. Despite being worse, though, the human-writtens stories had a much wider range of ideas and concepts in them. AI guidance provided the authors a higher-scoring work, but at the expense of actually being unique!\nTo abuse a quote: “all human work improved by AI is alike; every purely human work is creative in its own way.”\nIn future chapters we’ll dig deeper into how AI tools like ChatGPT work, and how a side effect of their construction might mean that headline generation is the only thing they’re reasonably good at! So whether you were super excited or roundly unimpressed: get excited for a ride down to the bottom."
  },
  {
    "objectID": "headlines/conclusion.html#footnotes",
    "href": "headlines/conclusion.html#footnotes",
    "title": "The big reveal",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAgain, big shout-out to Sisi Wei of The Markup for this one, which she suggested during a panel at ONA23. Seeing how much better the human-generated headlines can often do a fair job shocking you out of your ❤️ of AI-geneated headlines.↩︎\nI can’t find it! Only this one that is only kind of related. I promise it’s real, though: if you let AI help you, you’re probably more boring than an actual human (although yes, your story will be better written).↩︎"
  },
  {
    "objectID": "headlines/016-headline-suggestion copy 2.html",
    "href": "headlines/016-headline-suggestion copy 2.html",
    "title": "AI Workbook for Journalists",
    "section": "",
    "text": "We can all agree that writing headlines is the most horrific thing journalists have to endure. Let’s see what we can do to solve that problem!\nLet’s just… ask ChatGPT. Easy-peasy.\nYour mission has two parts:\nThe first part is to open up ChatGPT.\nThe second part is to find a news article that you’d like to have a headline generated for. It’s important that’s been published so you can compare the headline that’s generated to the headline that was actually published.\nI’m going to use this piece about drug use in the Bronx.\nWe’ll start by simply asking ChatGPT to generate a headline for us.\n**Write a headline for the story below:**\n\n(paste the story in)\n\n\n\n\n\n\nThe NYT article has ads and pictures and stuff halfway through – instead of selecting the full page of text I had to paste it in a few chunks.\n\n\n\nMy result says: **This is my result*\nIs it good? Is it bad?\nI find that using generative AI is a lot like going out to eat: even if something is objectively not wonderful, it seems great since you didn’t have to do the work. I encourage you to be as critical as possible of the results you’re getting back.\nLet’s try again, but this time we’ll give a little more guidance:\n**You are an editor for the New York Times. Write a headline for the story below. The tone should be informed but approachable. Limit the headline to 70 characters.**\n\n(paste the story in)\nNow it’s a bit shorter and the tone has shifted (I think?).\nIt still isn’t exactly perfect, which means we can try again. And again. And again. Each time nudging the headline in the direction we’re looking for. This is why ChatGPT is perfect for headline generation: it’s an iterative process.\nUnlike many other tasks where you want AI to do the entire job without interruption, headlines are both short enough and important enough that you (probably) want to be fully involved from start to finish.\nAs you change your prompt again and again, you start to note a bit of sameness about the headlines. They all seem to maybe have a similar tone, or a similar angle, or something that’s just… not as varied as when you’d ask a person to generate a handful of headlines.\nA way to get to this point faster is the rule of five. Instead of asking for one headline at a time, ask ChatGPT for five headlines.\n**You are an editor for the New York Times. Write five headline for the story below. The tone should be informed but approachable. Limit each headline to 70 characters.**\n\n(paste the story in)\nNow the similarities really jump out at you! We’re being gently guided into a certain direction, even if it’s completely by accident.\nI think calling this “bias” is a bit much, but it’s a gentle reminder that AI tools come with baked-in assumptions and angles. If you don’t pay attention to or notice them, at the very least they’ll make your headlines all similar and boring!\n\n\n\n\n\n\nNotice how even though I asked ChatGPT to not use subheads or colons, it did anyway! You should expect the AI to ignore your instructions a good portion of the time.\n\n\n\nAn extension of this approach might be to ask ChatGPT for five different angles, or five different tones.\nWrite five headlines for the story below. Limit each headline to around twelve words. Have each headline elicit a different emotional response from the reader. Label each headline with the emotion. Headlines should be elegant, and with the tone of the New Yorker. Don't use colons or multi-part headlines.\n\n(paste the story in)\nOnce we’ve gone this far, we’re probably going to end up picking a variation of one of the headlines that ChatGPT has suggested. But now the important part: how does it compare with the final headline the NYT used?\nThe NYT one is far more vague, less fear-inducing, and doesn’t mention the Bronx at all. It makes it a story relevant to all New Yorkers, but doesn’t turn it into fearmongering clickbait.\nHonestly, I was shocked: it’s so far from anything that GPT suggested.\nI read paper a while ago about story generation from humans and humans assisted by AI. Humans alone performed worse on average, but also had a much wider range of ideas and concepts brought into the stories. AI-assisted stories were better, but also more similar to each other. To abuse a quote, “all uncreative human work improved by AI is alike; every skilled creative human work is interesting in its own way.”"
  },
  {
    "objectID": "headlines/016-headline-suggestion copy 2.html#headline-suggestions",
    "href": "headlines/016-headline-suggestion copy 2.html#headline-suggestions",
    "title": "AI Workbook for Journalists",
    "section": "",
    "text": "We can all agree that writing headlines is the most horrific thing journalists have to endure. Let’s see what we can do to solve that problem!\nLet’s just… ask ChatGPT. Easy-peasy.\nYour mission has two parts:\nThe first part is to open up ChatGPT.\nThe second part is to find a news article that you’d like to have a headline generated for. It’s important that’s been published so you can compare the headline that’s generated to the headline that was actually published.\nI’m going to use this piece about drug use in the Bronx.\nWe’ll start by simply asking ChatGPT to generate a headline for us.\n**Write a headline for the story below:**\n\n(paste the story in)\n\n\n\n\n\n\nThe NYT article has ads and pictures and stuff halfway through – instead of selecting the full page of text I had to paste it in a few chunks.\n\n\n\nMy result says: **This is my result*\nIs it good? Is it bad?\nI find that using generative AI is a lot like going out to eat: even if something is objectively not wonderful, it seems great since you didn’t have to do the work. I encourage you to be as critical as possible of the results you’re getting back.\nLet’s try again, but this time we’ll give a little more guidance:\n**You are an editor for the New York Times. Write a headline for the story below. The tone should be informed but approachable. Limit the headline to 70 characters.**\n\n(paste the story in)\nNow it’s a bit shorter and the tone has shifted (I think?).\nIt still isn’t exactly perfect, which means we can try again. And again. And again. Each time nudging the headline in the direction we’re looking for. This is why ChatGPT is perfect for headline generation: it’s an iterative process.\nUnlike many other tasks where you want AI to do the entire job without interruption, headlines are both short enough and important enough that you (probably) want to be fully involved from start to finish.\nAs you change your prompt again and again, you start to note a bit of sameness about the headlines. They all seem to maybe have a similar tone, or a similar angle, or something that’s just… not as varied as when you’d ask a person to generate a handful of headlines.\nA way to get to this point faster is the rule of five. Instead of asking for one headline at a time, ask ChatGPT for five headlines.\n**You are an editor for the New York Times. Write five headline for the story below. The tone should be informed but approachable. Limit each headline to 70 characters.**\n\n(paste the story in)\nNow the similarities really jump out at you! We’re being gently guided into a certain direction, even if it’s completely by accident.\nI think calling this “bias” is a bit much, but it’s a gentle reminder that AI tools come with baked-in assumptions and angles. If you don’t pay attention to or notice them, at the very least they’ll make your headlines all similar and boring!\n\n\n\n\n\n\nNotice how even though I asked ChatGPT to not use subheads or colons, it did anyway! You should expect the AI to ignore your instructions a good portion of the time.\n\n\n\nAn extension of this approach might be to ask ChatGPT for five different angles, or five different tones.\nWrite five headlines for the story below. Limit each headline to around twelve words. Have each headline elicit a different emotional response from the reader. Label each headline with the emotion. Headlines should be elegant, and with the tone of the New Yorker. Don't use colons or multi-part headlines.\n\n(paste the story in)\nOnce we’ve gone this far, we’re probably going to end up picking a variation of one of the headlines that ChatGPT has suggested. But now the important part: how does it compare with the final headline the NYT used?\nThe NYT one is far more vague, less fear-inducing, and doesn’t mention the Bronx at all. It makes it a story relevant to all New Yorkers, but doesn’t turn it into fearmongering clickbait.\nHonestly, I was shocked: it’s so far from anything that GPT suggested.\nI read paper a while ago about story generation from humans and humans assisted by AI. Humans alone performed worse on average, but also had a much wider range of ideas and concepts brought into the stories. AI-assisted stories were better, but also more similar to each other. To abuse a quote, “all uncreative human work improved by AI is alike; every skilled creative human work is interesting in its own way.”"
  },
  {
    "objectID": "headlines/basics.html",
    "href": "headlines/basics.html",
    "title": "The value of chatting",
    "section": "",
    "text": "We can all agree that writing headlines is the most horrific thing journalists have to endure. Let’s see what we can do to solve that problem!\nStart by finding a news article that you’d like to have a headline generated for. It’s important that the story has been published so you can compare the headline that’s generated to the headline that was actually published.1\nI’m going to use this piece about drug use in the Bronx. If you don’t have your own story, no worries – you’ll be able to click buttons to use mine instead.\n\n\n\n\n\n\nThe NYT article has ads and pictures and other non-content partway through. Instead of selecting the full page of text I had to paste it in a few chunks.\n\n\n\n\n\n\n\n    \n\n\nOnce you’ve found an article you’d like to use, we’ll start by simply asking the AI to write a headline for us.\nClick here to use my article 🔮\nCut and paste the sample prompt below into the chat box to the right, replacing the placeholder text with the content of your story.\n\n\n\n\n\n\nPrompt suggestion\n\n\n\nWrite a headline for the article below:\n(paste the text of the story in)\n\n\nPress enter or click the send button to ask the chat bot to write the headline.\nA prompt is any time you text to a chatbot and ask for a response. Take a moment to think about the chatbot’s response to your prompt. How did it do?\n\n\nMy result was a little more intense than I’d have liked, but correctly noted the location and one of the major points of conflict in the story:\n\nBronx Drug Crisis Intensifies Amid Overdose Spike, Highlighting Citywide Dilemma Over Enforcement and Decriminalization.\n\nAt first glance this seems great. But should we run right off to publish it?\nI find that using generative AI is a lot like going out to eat: even if a result is objectively mediocre, it reflexively seems great since you didn’t have to do the work. It might take some addition effort, but I know we can find some things wrong with it!\nNo matter how you feel about decriminalization and dramatic headlines, there’s one thing we can all agree on: this headline is way way way too long.\n\n\n\nThe greatest strength of AI chatbots like ChatGPT is that they are built around having conversations, and they understand and remember context. That means you can provide feedback and ask follow-up questions, guiding the headline to be closer and closer to what you want.\nUnlike many other tasks where you want AI to do the entire job without interruption, headlines are both short enough and important enough that you (probably) want to be fully involved from start to finish!\n\nWe commonly use the word “context” to mean “the subject matter and general gist of a conversation.” It actually has a special meaning when it comes to AI! We’ll talk about it more in a later chapter, but right now it’s the amount of the conversation the AI can remember. If you talk for long enough it will forget the beginning!\n\n\n\nHave a conversation with the bot to fix up your headline a bit. Nudge it a few times until you get to something you’re more comfortable with!\nDirections to give the chatbot might include revising the length, tone, story angle, and objectivity/emotional appeal.\n\n\n\n\n\n\nPrompt suggestions\n\n\n\n\nRevise the headline no more than 10 words\nFocus on the inclusion and danger to children\nRewrite the headline in the style of the New York Times\nRewrite the headline as sensationalist, provocative, and punchy\n\n\n\nConsider this a tiny, tiny starting point: there are a lot of other aspects you can fool around with.\nAsk to make the headline shorter 🔮\nAsk for a stronger emotional appeal 🔮\nAsk for a less sensational headline 🔮\n\n\n\nNotice that my suggested prompts include two different types of tone changes: one asks in the style of a certain publication, while the other includes adjectives specifically describing the tone.\nInstead of “sensationalist, provocative, and punchy” I could have said “in the style of the New York Post.” Would that be a more effective shorthand in communicating to the chatbot, or is a specific description more successful? You only know by experimenting!\nAlso, it’s important to note that I picked those words to describe the New York Post because that’s how ChatGPT described it when I asked. If you can’t quite put your finger on what makes a certain outlet sound the way it does, ChatGPT is a fantastic resource:\n\nThe tone of the New York Post?\nThe tone of The New York Times?\n\nAlthough note that ChatGPT doesn’t mention the NYT’s strange relationship to prepositional phrases, so you might still be missing characteristic elements.\n\n\n\n\n\n\n\nAfter a few rounds of edits, I got tired of making demands of the chatbot and ended up with:\n\nCommunity Faces Dual Challenge: Drug Use and Public Safety\n\nThat is… awful, honestly. Far worse than the original one!\nBut even though I ended up in a place I didn’t like, along the way we developed a list of suggestions that will be in common for all of our headlines. A specific tone, a specific length, things to avoid or pay attention to.\nIn our next step we’ll use these notes to craft a single prompt that we can re-use for any story."
  },
  {
    "objectID": "headlines/basics.html#prompting-basics",
    "href": "headlines/basics.html#prompting-basics",
    "title": "The value of chatting",
    "section": "",
    "text": "Once you’ve found an article you’d like to use, we’ll start by simply asking the AI to write a headline for us.\nClick here to use my article 🔮\nCut and paste the sample prompt below into the chat box to the right, replacing the placeholder text with the content of your story.\n\n\n\n\n\n\nPrompt suggestion\n\n\n\nWrite a headline for the article below:\n(paste the text of the story in)\n\n\nPress enter or click the send button to ask the chat bot to write the headline.\nA prompt is any time you text to a chatbot and ask for a response. Take a moment to think about the chatbot’s response to your prompt. How did it do?\n\n\nMy result was a little more intense than I’d have liked, but correctly noted the location and one of the major points of conflict in the story:\n\nBronx Drug Crisis Intensifies Amid Overdose Spike, Highlighting Citywide Dilemma Over Enforcement and Decriminalization.\n\nAt first glance this seems great. But should we run right off to publish it?\nI find that using generative AI is a lot like going out to eat: even if a result is objectively mediocre, it reflexively seems great since you didn’t have to do the work. It might take some addition effort, but I know we can find some things wrong with it!\nNo matter how you feel about decriminalization and dramatic headlines, there’s one thing we can all agree on: this headline is way way way too long.\n\n\n\nThe greatest strength of AI chatbots like ChatGPT is that they are built around having conversations, and they understand and remember context. That means you can provide feedback and ask follow-up questions, guiding the headline to be closer and closer to what you want.\nUnlike many other tasks where you want AI to do the entire job without interruption, headlines are both short enough and important enough that you (probably) want to be fully involved from start to finish!\n\nWe commonly use the word “context” to mean “the subject matter and general gist of a conversation.” It actually has a special meaning when it comes to AI! We’ll talk about it more in a later chapter, but right now it’s the amount of the conversation the AI can remember. If you talk for long enough it will forget the beginning!\n\n\n\nHave a conversation with the bot to fix up your headline a bit. Nudge it a few times until you get to something you’re more comfortable with!\nDirections to give the chatbot might include revising the length, tone, story angle, and objectivity/emotional appeal.\n\n\n\n\n\n\nPrompt suggestions\n\n\n\n\nRevise the headline no more than 10 words\nFocus on the inclusion and danger to children\nRewrite the headline in the style of the New York Times\nRewrite the headline as sensationalist, provocative, and punchy\n\n\n\nConsider this a tiny, tiny starting point: there are a lot of other aspects you can fool around with.\nAsk to make the headline shorter 🔮\nAsk for a stronger emotional appeal 🔮\nAsk for a less sensational headline 🔮\n\n\n\nNotice that my suggested prompts include two different types of tone changes: one asks in the style of a certain publication, while the other includes adjectives specifically describing the tone.\nInstead of “sensationalist, provocative, and punchy” I could have said “in the style of the New York Post.” Would that be a more effective shorthand in communicating to the chatbot, or is a specific description more successful? You only know by experimenting!\nAlso, it’s important to note that I picked those words to describe the New York Post because that’s how ChatGPT described it when I asked. If you can’t quite put your finger on what makes a certain outlet sound the way it does, ChatGPT is a fantastic resource:\n\nThe tone of the New York Post?\nThe tone of The New York Times?\n\nAlthough note that ChatGPT doesn’t mention the NYT’s strange relationship to prepositional phrases, so you might still be missing characteristic elements."
  },
  {
    "objectID": "headlines/basics.html#reflection",
    "href": "headlines/basics.html#reflection",
    "title": "The value of chatting",
    "section": "",
    "text": "My result was a little more intense than I’d have liked, but correctly noted the location and one of the major points of conflict in the story:\n\nBronx Drug Crisis Intensifies Amid Overdose Spike, Highlighting Citywide Dilemma Over Enforcement and Decriminalization.\n\nAt first glance this seems great. But should we run right off to publish it?\nI find that using generative AI is a lot like going out to eat: even if a result is objectively mediocre, it reflexively seems great since you didn’t have to do the work. It might take some addition effort, but I know we can find some things wrong with it!\nNo matter how you feel about decriminalization and dramatic headlines, there’s one thing we can all agree on: this headline is way way way too long."
  },
  {
    "objectID": "headlines/basics.html#taking-feedback",
    "href": "headlines/basics.html#taking-feedback",
    "title": "The value of chatting",
    "section": "",
    "text": "The greatest strength of AI chatbots like ChatGPT is that they are built around having conversations, and they understand and remember context. That means you can provide feedback and ask follow-up questions, guiding the headline to be closer and closer to what you want.\nUnlike many other tasks where you want AI to do the entire job without interruption, headlines are both short enough and important enough that you (probably) want to be fully involved from start to finish!\n\nWe commonly use the word “context” to mean “the subject matter and general gist of a conversation.” It actually has a special meaning when it comes to AI! We’ll talk about it more in a later chapter, but right now it’s the amount of the conversation the AI can remember. If you talk for long enough it will forget the beginning!\n\n\n\nHave a conversation with the bot to fix up your headline a bit. Nudge it a few times until you get to something you’re more comfortable with!\nDirections to give the chatbot might include revising the length, tone, story angle, and objectivity/emotional appeal.\n\n\n\n\n\n\nPrompt suggestions\n\n\n\n\nRevise the headline no more than 10 words\nFocus on the inclusion and danger to children\nRewrite the headline in the style of the New York Times\nRewrite the headline as sensationalist, provocative, and punchy\n\n\n\nConsider this a tiny, tiny starting point: there are a lot of other aspects you can fool around with.\nAsk to make the headline shorter 🔮\nAsk for a stronger emotional appeal 🔮\nAsk for a less sensational headline 🔮\n\n\n\nNotice that my suggested prompts include two different types of tone changes: one asks in the style of a certain publication, while the other includes adjectives specifically describing the tone.\nInstead of “sensationalist, provocative, and punchy” I could have said “in the style of the New York Post.” Would that be a more effective shorthand in communicating to the chatbot, or is a specific description more successful? You only know by experimenting!\nAlso, it’s important to note that I picked those words to describe the New York Post because that’s how ChatGPT described it when I asked. If you can’t quite put your finger on what makes a certain outlet sound the way it does, ChatGPT is a fantastic resource:\n\nThe tone of the New York Post?\nThe tone of The New York Times?\n\nAlthough note that ChatGPT doesn’t mention the NYT’s strange relationship to prepositional phrases, so you might still be missing characteristic elements."
  },
  {
    "objectID": "headlines/basics.html#conclusion",
    "href": "headlines/basics.html#conclusion",
    "title": "The value of chatting",
    "section": "",
    "text": "After a few rounds of edits, I got tired of making demands of the chatbot and ended up with:\n\nCommunity Faces Dual Challenge: Drug Use and Public Safety\n\nThat is… awful, honestly. Far worse than the original one!\nBut even though I ended up in a place I didn’t like, along the way we developed a list of suggestions that will be in common for all of our headlines. A specific tone, a specific length, things to avoid or pay attention to.\nIn our next step we’ll use these notes to craft a single prompt that we can re-use for any story."
  },
  {
    "objectID": "headlines/basics.html#footnotes",
    "href": "headlines/basics.html#footnotes",
    "title": "The value of chatting",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis idea is courtesy Sisi Wei of The Markup. On a panel at ONA23 she mentioned that she doesn’t use ChatGPT for headlines, but likes to plug stories in after publication and then ask for headlines, just to be able to say “no no no, we could never use that!”↩︎"
  },
  {
    "objectID": "headlines/prompt-engineering.html",
    "href": "headlines/prompt-engineering.html",
    "title": "AI Workbook for Journalists",
    "section": "",
    "text": "Let’s start from the top again. Instead of just asking for a headline for our story and then spending our time adjusting it, we’ll provide plenty of guidance about what we’re looking for up front.\nFiguring out what to ask when you’re looking for a response is called prompt engineering, and it’s often the difference between a successful request and a failed one!\nOpenAI, the organization behind ChatGPT, has an entire guide on prompt engineering, full of concrete suggestions. Under “Write clear instructions,” they provide the following tips:\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output\n\nThere are a ton of guides out there to help with your prompting. If you have a little more time I suggest taking a look at Ethan Mollick’s prompting guide, which is a little more conceptual.\n\nWhen you start to read about how to interact with AI tools like ChatGPT, you start to see the term language model or large language model again and again. That’s just the “brains” of the chatbot, the software that allows it to come up with responses to your requests. We’ll talk more about the specifics in a later chapter!"
  },
  {
    "objectID": "headlines/prompt-engineering.html#prompt-engineering",
    "href": "headlines/prompt-engineering.html#prompt-engineering",
    "title": "AI Workbook for Journalists",
    "section": "",
    "text": "Let’s start from the top again. Instead of just asking for a headline for our story and then spending our time adjusting it, we’ll provide plenty of guidance about what we’re looking for up front.\nFiguring out what to ask when you’re looking for a response is called prompt engineering, and it’s often the difference between a successful request and a failed one!\nOpenAI, the organization behind ChatGPT, has an entire guide on prompt engineering, full of concrete suggestions. Under “Write clear instructions,” they provide the following tips:\n\nInclude details in your query to get more relevant answers\nAsk the model to adopt a persona\nUse delimiters to clearly indicate distinct parts of the input\nSpecify the steps required to complete a task\nProvide examples\nSpecify the desired length of the output\n\nThere are a ton of guides out there to help with your prompting. If you have a little more time I suggest taking a look at Ethan Mollick’s prompting guide, which is a little more conceptual.\n\nWhen you start to read about how to interact with AI tools like ChatGPT, you start to see the term language model or large language model again and again. That’s just the “brains” of the chatbot, the software that allows it to come up with responses to your requests. We’ll talk more about the specifics in a later chapter!"
  },
  {
    "objectID": "headlines/prompt-engineering.html#exercise",
    "href": "headlines/prompt-engineering.html#exercise",
    "title": "AI Workbook for Journalists",
    "section": "Exercise",
    "text": "Exercise\n\n\n    \n\n\nLet’s see if we can get a single prompt that will generate a great headline right out of the gate!\nCombine the suggestions above with the directions you nudged the headline in the last exercise to craft a winning request.\n\n\n\n\n\n\nA prompt suggestion\n\n\n\nYou are an editor at the New York Times. Write a headline for the article below. The tone should be informed but approachable. Limit the headline to 70 characters.\nARTICLE:\n(paste the story in)\n\n\nClick here to use my article 🔮\nPrompt engineering is a lot like magic: special words you chant to an unknown being that, without rhyme or reason, might cause something amazing to spill forth. It definitely takes practice to get the hang of getting good responses!\nBefore you get too deep into tweaking the prompt towards a “best” result, you might want to read the next section…\n\nThe danger of conversation\nOne important thing to note is that while context is usually a great thing for ChatGPT to have, a conversation can actually ruin a prompt!\nChatGPT and other AI tools take your entire conversation into account when generating their responses, which can lead to unexpected results:\nIf you’ve already prompted for a science story about snails and slugs, your headline request for an article about stock prices might be subtlely affected! The AI might cite facts or concepts from the earlier story, or “feel” the unnecessary need to address the middle ground between snails and stocks.\nIt gets even worse if you’re asking for jokes, poems or dating advice, then pivoting to headline suggestions. Keep to new conversations as much as possible to prevent content pollution and cross-pollination between prompts.\nEven computer-y folks miss out on this! A memorable moment was this tweet where someone is kinda dunking on their mom for not using ChatGPT “correctly:”\n\n\n\ngave my mom access to my ChatGPT account and found out she’s making new chats for every single prompt & has created over 300 “new chats” in the past week alone\n\n\n…and king of LLMs Simon Willison shows up with the facts:\n\n\n\nStarting a new chat for each query is a good idea. It’s only worth reusing an existing chat if you’re asking follow-up questions around the same topic\n\n\nGood work, mom! So now let me introduce you to a very useful button:\nClear the chat 🔮\n\n\nThe help of suggestions\nWhen you ask an AI tool to do something without providing any examples, this is called a “zero shot” approach. You’re fully relying on the language model’s understanding of what you’re asking for.\nImagine you had a junior editor you were guiding along, though: you’d probably show them some examples of headlines that worked and headlines that didn’t. You can do the same thing with AI with what is called few-shot prompting. This is what OpenAI means in their guide where they mention “Provide examples” (see above).\n\n\n\n\n\n\nA prompt suggestion\n\n\n\nYou are an editor at the New York Times. Write a headline for the story below. The tone should be informed but approachable. Limit the headline to 70 characters. Don’t use colons or subheads. Move prepositional phrases to the start of the headline.\nGood example: On Twitter, Sifting Through Falsehoods in Critical Times\nBad example: Meet the 4 Dem-picked Colorado justices who kicked ex-prez off the ballot\nARTICLE:\n(paste the story in)\n\n\nClick here to use my article 🔮\nClear the chat 🔮\nWhen you get to a prompt you think does a pretty good job, save it. We’ll make it even better in the next step!\n\n\nReflection\nNow it’s a bit shorter and the tone has shifted a little bit:\n\nNear Bronx Day Care, Open Drug Market Persists Amid Fentanyl Crisis\n\nI think it’s better, but again: it’s difficult to be critical of something that comes out like magic! But the sharper the eye you can take to it, the more suggestions we can provide in the prompt.\nAs we had the conversation about our headlines in the last step, you probably noticed a bit of sameness about the headlines. They all seemed to maybe have a similar tone, or a similar angle, or something that’s just… not as varied as when you’d ask a person to generate a handful of headlines.\nOne downside of having a fine-tuned prompt ready to go is you might just take the first response as the gospel truth: no need to wait for something better, we’ve given it as much guidance as we have! But by only seeing one example, we might not notice the preferences or biases or assumptions that the tool is working with.\nOur next step will fix that right up!"
  },
  {
    "objectID": "headlines/prompt-engineering.html#the-danger-of-conversation",
    "href": "headlines/prompt-engineering.html#the-danger-of-conversation",
    "title": "AI Workbook for Journalists",
    "section": "The danger of conversation",
    "text": "The danger of conversation\nOne important thing to note is that while context is usually a great thing for ChatGPT to have, a conversation can actually ruin a prompt!\nChatGPT and other AI tools take your entire conversation into account when generating their responses, which can lead to unexpected results:\nIf you’ve already prompted for a science story about snails and slugs, your headline request for an article about stock prices might be subtlely affected! The AI might cite facts or concepts from the earlier story, or “feel” the unnecessary need to address the middle ground between snails and stocks.\nIt gets even worse if you’re asking for jokes, poems or dating advice, then pivoting to headline suggestions. Keep to new conversations as much as possible to prevent content pollution and cross-pollination between prompts.\nEven computer-y folks miss out on this! A memorable moment was this tweet where someone is kinda dunking on their mom for not using ChatGPT “correctly:”\n\n\n\ngave my mom access to my ChatGPT account and found out she’s making new chats for every single prompt & has created over 300 “new chats” in the past week alone\n\n\n…and king of LLMs Simon Willison shows up with the facts:\n\n\n\nStarting a new chat for each query is a good idea. It’s only worth reusing an existing chat if you’re asking follow-up questions around the same topic\n\n\nGood work, mom! So now let me introduce you to a very useful button:\nClear the chat 🔮"
  },
  {
    "objectID": "headlines/prompt-engineering.html#the-help-of-suggestions",
    "href": "headlines/prompt-engineering.html#the-help-of-suggestions",
    "title": "AI Workbook for Journalists",
    "section": "The help of suggestions",
    "text": "The help of suggestions\nWhen you ask an AI tool to do something without providing any examples, this is called a “zero shot” approach. You’re fully relying on the language model’s understanding of what you’re asking for.\nImagine you had a junior editor you were guiding along, though: you’d probably show them some examples of headlines that worked and headlines that didn’t. You can do the same thing with AI with what is called few-shot prompting. This is what OpenAI means in their guide where they mention “Provide examples” (see above).\n\n\n\n\n\n\nA prompt suggestion\n\n\n\nYou are an editor at the New York Times. Write a headline for the story below. The tone should be informed but approachable. Limit the headline to 70 characters. Don’t use colons or subheads. Move prepositional phrases to the start of the headline.\nGood example: On Twitter, Sifting Through Falsehoods in Critical Times\nBad example: Meet the 4 Dem-picked Colorado justices who kicked ex-prez off the ballot\nARTICLE:\n(paste the story in)\n\n\nClick here to use my article 🔮\nClear the chat 🔮\nWhen you get to a prompt you think does a pretty good job, save it. We’ll make it even better in the next step!"
  },
  {
    "objectID": "headlines/prompt-engineering.html#reflection",
    "href": "headlines/prompt-engineering.html#reflection",
    "title": "AI Workbook for Journalists",
    "section": "Reflection",
    "text": "Reflection\nNow it’s a bit shorter and the tone has shifted a little bit:\n\nNear Bronx Day Care, Open Drug Market Persists Amid Fentanyl Crisis\n\nI think it’s better, but again: it’s difficult to be critical of something that comes out like magic! But the sharper the eye you can take to it, the more suggestions we can provide in the prompt.\nAs we had the conversation about our headlines in the last step, you probably noticed a bit of sameness about the headlines. They all seemed to maybe have a similar tone, or a similar angle, or something that’s just… not as varied as when you’d ask a person to generate a handful of headlines.\nOne downside of having a fine-tuned prompt ready to go is you might just take the first response as the gospel truth: no need to wait for something better, we’ve given it as much guidance as we have! But by only seeing one example, we might not notice the preferences or biases or assumptions that the tool is working with.\nOur next step will fix that right up!"
  },
  {
    "objectID": "140-automation-in-general.html",
    "href": "140-automation-in-general.html",
    "title": "Automation in general",
    "section": "",
    "text": "Automation in general\nResponses change"
  },
  {
    "objectID": "020-article-summarization.html",
    "href": "020-article-summarization.html",
    "title": "AI Workbook for Journalists",
    "section": "",
    "text": "Next up: we need AI to summarize an article, to write a blurb for social media or the homepage or whatever.\nSummarize the article below.\n\n(paste the article in)\nOK. We can add some parameters: length, tone, etc.\nSummarize the article below. It should sound like the New York Times, informed but approachable. Limit the summary to 70 words.\n\n(paste the article in)\nIs that really the NYT tone? Is it actually 70 words? No, but it’s vaguely in the area.\nGPT can’t actually count, it doesn’t actually know what the NYT is. But due to the magic of large language models, it kinda works out anyway.\n\n\n\n\n\n\nI’m not 100% joking when I say “the magic of LLMs” – even the people building them are often surprised at how well they perform tasks like these! It doesn’t mean they’re conscious celestial beings, just that complex systems can sometimes have surprising emergent properties.\n\n\n\nArticle summaries are typically useful for people who are not the author – someone who is writing social posts, or blurbs for homepages or newsletters, or other supporting cases. So instead of cutting and pasting into ChatGPT and having a knowledgeable conversation until it gets just right, you’ll probably want to build it into your CMS workflow or something.\nThat is called using an API - a way for computers to talk to each other. Your CMS can send the article to OpenAI’s API, get back a summary, and then you can use that summary in your CMS. Easy-peasy route for you to allow other folks to use the tool.\nYou might have one prompt for the newsletter, one for Twitter posts, one for the homepage. And all these people who are taking on the summary, you’ve just increased their workflow by 100x because they don’t have to actually read the article! And the code to put it together is really easy, it’s just something like:\nimport openai\n\n# blah blah get the summary\nNow you try it. Write a prompt that just works, about an article that you know about.\nsteal things from the talk\nNow: how comfortable would you be letting this automatically generate a summary for you? You know the story in-depth, that’s fine, you can change it to be what you want. But what about a social media personn, or an editor in charge of a homepage? They might not be familiar, so the fact that the tone is off, or it’s focusing on something that isn’t important… that might be an issue. But there’s a bigger one.\nPlay around with this for a little while and you’ll quickly get a summary that is factually incorrect. Not just a different tone, not just a different focus, but wholly incorrect.\nYou might have heard of hallucinations before, of LLMs getting things wrong. Maybe they don’t know who the current president is, or they make up a book that someone wrote. You might expect this when it’s talking about its giant brain full of infinite knowledge, but it can also happen in a situation as simple as summarizing a short article!\nLLMs are a machine that predict the next word. (hungry/starving/famished).\nBased on the previous words, it will usually tell you something correct. But GPT doesn’t actually understand anything. It doesn’t understand concepts or ideas or what makes sense or what doesn’t. This is an inherent technical limitation. People are trying their best to engineer around it, but no matter what you’re told by an AI hype person (or well-meaning vendor) incorrect summarizations are absolutely a possibility.\nWelcome to the danger zone.\nHeadline generation is a much easier problem for a few reasons:\n\nHeadlines are short so you don’t mind generating a handful to compare\nThe person requesting the headlines is very familiar with the story, so they can notice if something is off\n\nWriting a longer blurb as a person not closely affiliated with the story gives us many more opportunities for things to go wrong. Not just hallucinations, but tone and angles and a hundred other tiny things.\nSo how can we deal with that? Maybe the LLM rarely hallucinates, maybe it always does, maybe half the time the tone is wrong? Everyone has a different experience, and someone who is excited about AI is going to let a lot more things slip through and someone who is angry about AI is not going to give it any slack.\nThe answer to this might be to not use AI, but I have another suggestion: every time you use AI in your newsroom, I want you to track it.\nTesting and tracking infrastructure is absolutely necessary when using these tools. How often does it work, how often does it not, and what kinds of errors appear when it’s wrong?\nIt’s easy to get enchanted by the fact that AI is doing work for you, and not think about whether it’s actually saving you time or giving you a valuable result. It’s definitely magic, but sometimes magic isn’t actually useful!\nMy favorite example is about Danish article summaries, published on The Generative AI Newsroom: https://generative-ai-newsroom.com/summaries-in-danish-with-openai-cbb814a119f2. The author keeps track of every summary, whether it worked, and if it didn’t want the shortcoming was. Look at this piece of beauty:\n\n92 articles were given an accepted summary. 54 of the articles were given an acceptable summary in the first attempt (59%), while the remaining 38 articles took several attempts. A total of 193 summaries were generated, of which 101 summaries were rejected. We didn’t give up on any articles.\nThe rejected 101 summaries fell into the following categories [number of articles] (number of summaries):\n\nMissing important information [14] (28)\nIncorrect summary [14] (23)\nAI evaluates content [9] (17) (e.g. the model states that the company has had a successful year)\nPoor language [9] (12)\nIrrelevant information [4] (6)\nAI adds own content [2] (7)\nWrong translation [2] (4)\nMentioning what is missing [1] (2) (e.g. the model adds: “the company does not provide further information about the reason for the unsatisfactory result”)\nAI not aware of public knowledge [1] (1) (the model has limited knowledge of the world and events after 2021, which is evident in the summary. In this case, the model is unaware of a fatal accident that is widely publicized.)\nSummary too long [1] (1)\n\n\nThis was instead of saying “it feels like magic” or “I think I had to click ‘rengenerate’ a bunch” you get actual metrics to help show you whether the process is working or not.\nOnce you have those metrics, you have an actionable baseline to know whether it’s worth implementing these tools in your newsroom."
  },
  {
    "objectID": "020-article-summarization.html#article-summarization-and-blurbs",
    "href": "020-article-summarization.html#article-summarization-and-blurbs",
    "title": "AI Workbook for Journalists",
    "section": "",
    "text": "Next up: we need AI to summarize an article, to write a blurb for social media or the homepage or whatever.\nSummarize the article below.\n\n(paste the article in)\nOK. We can add some parameters: length, tone, etc.\nSummarize the article below. It should sound like the New York Times, informed but approachable. Limit the summary to 70 words.\n\n(paste the article in)\nIs that really the NYT tone? Is it actually 70 words? No, but it’s vaguely in the area.\nGPT can’t actually count, it doesn’t actually know what the NYT is. But due to the magic of large language models, it kinda works out anyway.\n\n\n\n\n\n\nI’m not 100% joking when I say “the magic of LLMs” – even the people building them are often surprised at how well they perform tasks like these! It doesn’t mean they’re conscious celestial beings, just that complex systems can sometimes have surprising emergent properties.\n\n\n\nArticle summaries are typically useful for people who are not the author – someone who is writing social posts, or blurbs for homepages or newsletters, or other supporting cases. So instead of cutting and pasting into ChatGPT and having a knowledgeable conversation until it gets just right, you’ll probably want to build it into your CMS workflow or something.\nThat is called using an API - a way for computers to talk to each other. Your CMS can send the article to OpenAI’s API, get back a summary, and then you can use that summary in your CMS. Easy-peasy route for you to allow other folks to use the tool.\nYou might have one prompt for the newsletter, one for Twitter posts, one for the homepage. And all these people who are taking on the summary, you’ve just increased their workflow by 100x because they don’t have to actually read the article! And the code to put it together is really easy, it’s just something like:\nimport openai\n\n# blah blah get the summary\nNow you try it. Write a prompt that just works, about an article that you know about.\nsteal things from the talk\nNow: how comfortable would you be letting this automatically generate a summary for you? You know the story in-depth, that’s fine, you can change it to be what you want. But what about a social media personn, or an editor in charge of a homepage? They might not be familiar, so the fact that the tone is off, or it’s focusing on something that isn’t important… that might be an issue. But there’s a bigger one.\nPlay around with this for a little while and you’ll quickly get a summary that is factually incorrect. Not just a different tone, not just a different focus, but wholly incorrect.\nYou might have heard of hallucinations before, of LLMs getting things wrong. Maybe they don’t know who the current president is, or they make up a book that someone wrote. You might expect this when it’s talking about its giant brain full of infinite knowledge, but it can also happen in a situation as simple as summarizing a short article!\nLLMs are a machine that predict the next word. (hungry/starving/famished).\nBased on the previous words, it will usually tell you something correct. But GPT doesn’t actually understand anything. It doesn’t understand concepts or ideas or what makes sense or what doesn’t. This is an inherent technical limitation. People are trying their best to engineer around it, but no matter what you’re told by an AI hype person (or well-meaning vendor) incorrect summarizations are absolutely a possibility.\nWelcome to the danger zone.\nHeadline generation is a much easier problem for a few reasons:\n\nHeadlines are short so you don’t mind generating a handful to compare\nThe person requesting the headlines is very familiar with the story, so they can notice if something is off\n\nWriting a longer blurb as a person not closely affiliated with the story gives us many more opportunities for things to go wrong. Not just hallucinations, but tone and angles and a hundred other tiny things.\nSo how can we deal with that? Maybe the LLM rarely hallucinates, maybe it always does, maybe half the time the tone is wrong? Everyone has a different experience, and someone who is excited about AI is going to let a lot more things slip through and someone who is angry about AI is not going to give it any slack.\nThe answer to this might be to not use AI, but I have another suggestion: every time you use AI in your newsroom, I want you to track it.\nTesting and tracking infrastructure is absolutely necessary when using these tools. How often does it work, how often does it not, and what kinds of errors appear when it’s wrong?\nIt’s easy to get enchanted by the fact that AI is doing work for you, and not think about whether it’s actually saving you time or giving you a valuable result. It’s definitely magic, but sometimes magic isn’t actually useful!\nMy favorite example is about Danish article summaries, published on The Generative AI Newsroom: https://generative-ai-newsroom.com/summaries-in-danish-with-openai-cbb814a119f2. The author keeps track of every summary, whether it worked, and if it didn’t want the shortcoming was. Look at this piece of beauty:\n\n92 articles were given an accepted summary. 54 of the articles were given an acceptable summary in the first attempt (59%), while the remaining 38 articles took several attempts. A total of 193 summaries were generated, of which 101 summaries were rejected. We didn’t give up on any articles.\nThe rejected 101 summaries fell into the following categories [number of articles] (number of summaries):\n\nMissing important information [14] (28)\nIncorrect summary [14] (23)\nAI evaluates content [9] (17) (e.g. the model states that the company has had a successful year)\nPoor language [9] (12)\nIrrelevant information [4] (6)\nAI adds own content [2] (7)\nWrong translation [2] (4)\nMentioning what is missing [1] (2) (e.g. the model adds: “the company does not provide further information about the reason for the unsatisfactory result”)\nAI not aware of public knowledge [1] (1) (the model has limited knowledge of the world and events after 2021, which is evident in the summary. In this case, the model is unaware of a fatal accident that is widely publicized.)\nSummary too long [1] (1)\n\n\nThis was instead of saying “it feels like magic” or “I think I had to click ‘rengenerate’ a bunch” you get actual metrics to help show you whether the process is working or not.\nOnce you have those metrics, you have an actionable baseline to know whether it’s worth implementing these tools in your newsroom."
  },
  {
    "objectID": "080-categorizing-documents.html",
    "href": "080-categorizing-documents.html",
    "title": "Categorizing documents",
    "section": "",
    "text": "Categorizing documents\nThis one is easy. And it can often be wrong! But it’s resilient to wrong answers, because people could give you wrong answers X% of the time and any individual piece is probably not that important.\n(i’m not a downer! or is it?? gotta think about it!!)"
  },
  {
    "objectID": "060-semantic-search.html",
    "href": "060-semantic-search.html",
    "title": "Semantic search",
    "section": "",
    "text": "Semantic search\nWhat if we don’t want to generate content, though? What if we just want to search for it?\nExact word search\nNo! Text embeddings - vibe search\nNo exact answer tho it’s all opinions about similarity\nSome work across languages though which is cool\nBonuses: Generate potential answers and search for those, too. Downsides: nothing it’s awesome, but you should definitely combine with traditional keyword search though."
  },
  {
    "objectID": "130-data-cleaning.html",
    "href": "130-data-cleaning.html",
    "title": "Data cleaning",
    "section": "",
    "text": "Data cleaning\nidk"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI Workbook for Journalists",
    "section": "",
    "text": "This place is a little bare at the moment, but head on over to headlines and get started!"
  },
  {
    "objectID": "index.html#ai-workbook-for-journalists",
    "href": "index.html#ai-workbook-for-journalists",
    "title": "AI Workbook for Journalists",
    "section": "",
    "text": "This place is a little bare at the moment, but head on over to headlines and get started!"
  },
  {
    "objectID": "090-transcription.html",
    "href": "090-transcription.html",
    "title": "Translation",
    "section": "",
    "text": "Whisper rules\nCan run locally"
  },
  {
    "objectID": "110-translation.html",
    "href": "110-translation.html",
    "title": "Translation",
    "section": "",
    "text": "Translation\nI dunno I think it’s dangerous and mean to people who should have jobs and it’s disrespectful to the audiences you’re serving.\n“we couldn’t afford it otherwise” go fuck yourselves, news doesn’t need to scale I dno’t think.\nHow to test it."
  },
  {
    "objectID": "050-fundamental-flaws-of-llms.html",
    "href": "050-fundamental-flaws-of-llms.html",
    "title": "Fundamental flaws of LLMs for news",
    "section": "",
    "text": "LLMs cannot reason They do NOT have sources of information, they just keep predicting the next most likely word Don’t confuse style for substance\nLLMs can’t understand things we (people) take for granted Trust, integrity, or relative importance: not meaningful! Humans care: we pay more attention to important things\nThis is not really a “getting better” problem\n\n\nAudience vs journalist facing Testing and tracking"
  },
  {
    "objectID": "050-fundamental-flaws-of-llms.html#but-can-we-use-it-anyway",
    "href": "050-fundamental-flaws-of-llms.html#but-can-we-use-it-anyway",
    "title": "Fundamental flaws of LLMs for news",
    "section": "",
    "text": "Audience vs journalist facing Testing and tracking"
  },
  {
    "objectID": "120-text-to-speech.html",
    "href": "120-text-to-speech.html",
    "title": "Text to speech",
    "section": "",
    "text": "Format shifting between text and audio and if you combing all of these things.\n\n\nYou can even make it voice clone with how you’re talking, so if you’re excited or unexcited and you can lip sync and it gets really wild really quickly. You’ll use a service though because it’s a bunch of things connected to each other."
  },
  {
    "objectID": "120-text-to-speech.html#voice-cloning",
    "href": "120-text-to-speech.html#voice-cloning",
    "title": "Text to speech",
    "section": "",
    "text": "You can even make it voice clone with how you’re talking, so if you’re excited or unexcited and you can lip sync and it gets really wild really quickly. You’ll use a service though because it’s a bunch of things connected to each other."
  },
  {
    "objectID": "030-document-summaries.html",
    "href": "030-document-summaries.html",
    "title": "AI Workbook for Journalists",
    "section": "",
    "text": "People love to plug docs into GPT and get summaries. You don’t have to read the science paper! Etc!\nWhat’s the difference with “documents” as compared to last chapter’s “articles?” Documents and books and the like are longer.\nIf we try to paste a whole book or a long science paper into GPT, we get an error.\ntry it out\nContext window means we need to split it up and send it in chunks. There are a few ways to do this, but normally each chunk is summarized separately and then summarized together.\nHoo boy, what can go wrong?\nWe’ve established that we can have errors in summarization - what happens when we compound these?"
  },
  {
    "objectID": "030-document-summaries.html#document-summaries",
    "href": "030-document-summaries.html#document-summaries",
    "title": "AI Workbook for Journalists",
    "section": "",
    "text": "People love to plug docs into GPT and get summaries. You don’t have to read the science paper! Etc!\nWhat’s the difference with “documents” as compared to last chapter’s “articles?” Documents and books and the like are longer.\nIf we try to paste a whole book or a long science paper into GPT, we get an error.\ntry it out\nContext window means we need to split it up and send it in chunks. There are a few ways to do this, but normally each chunk is summarized separately and then summarized together.\nHoo boy, what can go wrong?\nWe’ve established that we can have errors in summarization - what happens when we compound these?"
  }
]